/******************************************************************************
 * Single Threadblock 8-bit LSD Radix Sort
 *
 * Author:  Thomas Smith 8/30/2023
 *
 * License: The Unlicense
 *          This is free and unencumbered software released into the public domain.
 *          For more information, please refer to the repository license or <https://unlicense.org>
 *
 ******************************************************************************/
#pragma use_dxc
#pragma kernel InitBlockRadixSort
#pragma kernel InitRandom
#pragma kernel GlobalHistogram
#pragma kernel FirstBinningPass
#pragma kernel SecBinningPass
#pragma kernel ThirdBinningPass
#pragma kernel FourthBinningPass

//General macros
#define LANE_COUNT          32      //Lanes per wave, Nvidia hardware
#define LANE_MASK           31      //Mask of the lane count
#define LANE_LOG            5       //log2(LANE_COUNT)
#define VEC_SIZE            4       //Size of a four element vector

#define RADIX               256     //Number of digit bins
#define RADIX_MASK          255     //Mask of digit bins
#define RADIX_LOG           8       //log2(RADIX)
#define SEC_RADIX           8       //Shift value to retrieve digits from the second place
#define THIRD_RADIX         16      //Shift value to retrieve digits from the third place
#define FOURTH_RADIX        24      //Shift value to retrieve digits from the fourth place 
#define SEC_RADIX_START     256     //Offset for retrieving values from global buffer
#define THIRD_RADIX_START   512     //Offset for retrieving values from global buffer
#define FOURTH_RADIX_START  768     //Offset for retrieving values from global buffer

#define LANE                gtid.x                                  //The lane of a thread
#define WAVE_INDEX          gtid.y                                  //The wave of a thread
#define GROUP_THREAD_ID     (LANE + (WAVE_INDEX << LANE_LOG))       //The group relative thread id

//For the upfront global histogram only
#define G_HIST_WAVES        32                                      //The number of waves in the GlobalHistogram threadblock
#define G_HIST_THREADS      1024                                    //The number of threads in the GlobalHistogram threadblock
#define G_HIST_SHARED_MEM   2048                                    //The vectorized shared memory requirement for the GlobalHistogram threadblock

#define G_HIST_W_G_INDEX    (WAVE_INDEX >> 2)                       //Collect waves into "Wave Groups" that each share a histogram
#define G_HIST_W_G_START    (G_HIST_W_G_INDEX << RADIX_LOG)         //Starting offset of a wave group histogram

//For the binning
#define BIN_PART_SIZE       7936                                    //The partition tile size of a BinningPass threadblock
#define BIN_THREADS         992                                     //The number of threads in a BinningPass threadblock
#define BIN_SUB_PART_SIZE   256                                     //The subpartition tile size of a single wave in a BinningPass threadblock
#define BIN_SUB_PART_LOG    8                                       //log2(BIN_SUB_PART_SIZE)
#define BIN_WAVES           31                                      //The number of waves in a BinningPass threadblock
#define BIN_KEY_VECS        2                                       //Size of the per thread vector array in a BinningPass threadblock

#define BIN_PARTITIONS      (e_size / BIN_PART_SIZE)                //The number of partition tiles in the BinningPass
#define BIN_PART_START      (partitionIndex * BIN_PART_SIZE)        //The starting offset of a BinningPass partition tile
#define BIN_SUB_PART_START  (WAVE_INDEX << BIN_SUB_PART_LOG)        //The starting offset of a BinningPass sub partition tile

//Hybrid LCG-Tausworthe PRNG
//From GPU GEMS 3, Chapter 37
//Authors: Lee Howes and David Thomas 
#define TAUS_STEP_1 ((z1 & 4294967294U) << 12) ^ (((z1 << 13) ^ z1) >> 19)
#define TAUS_STEP_2 ((z2 & 4294967288U) << 4) ^ (((z2 << 2) ^ z2) >> 25)
#define TAUS_STEP_3 ((z3 & 4294967280U) << 17) ^ (((z3 << 3) ^ z3) >> 11)
#define LCG_STEP    (z4 * 1664525 + 1013904223U)
#define HYBRID_TAUS (z1 ^ z2 ^ z3 ^ z4)

extern int e_size;                                                  //Input size, passed in from CPU
extern uint e_seed;                                                 //Seed for PRNGS, passed in from CPU

RWBuffer<uint> b_sort;                                              //buffer to be sorted
RWBuffer<uint> b_alt;                                               //double buffer
RWBuffer<uint> b_globalHist;                                        //buffer holding device level offsets for each binning pass
RWBuffer<uint> b_timing;                                            //To time the execution of the kernels

groupshared uint4 g_globalHist[G_HIST_SHARED_MEM];                  //Shared memory for performing the upfront global histogram
groupshared uint g_localHist[RADIX];                                //Threadgroup copy of globalHist during digit binning passes
groupshared uint g_waveHists[BIN_PART_SIZE];                        //Shared memory for the per wave histograms during digit binning passes

[numthreads(1024, 1, 1)]
void InitBlockRadixSort(int3 id : SV_DispatchThreadID)
{
    for (int i = id.x; i < e_size; i += 1024 * 256)
        b_sort[i] = e_size - i;
    
    for (int i = id.x; i < 1024; i += 1024 * 256)
        b_globalHist[i] = 0;
}

[numthreads(1024, 1, 1)]
void InitRandom(int3 id : SV_DispatchThreadID)
{
    uint z1 = (id.x << 2) * e_seed;
    uint z2 = ((id.x << 2) + 1) * e_seed;
    uint z3 = ((id.x << 2) + 2) * e_seed;
    uint z4 = ((id.x << 2) + 3) * e_seed;
    
    for (int i = id.x; i < e_size; i += 1024 * 256)
    {
        z1 = TAUS_STEP_1;
        z2 = TAUS_STEP_2;
        z3 = TAUS_STEP_3;
        z4 = LCG_STEP;
        b_sort[i] = HYBRID_TAUS;
    }
    
    for (int i = id.x; i < 1024; i += 1024 * 256)
        b_globalHist[i] = 0;
}

[numthreads(LANE_COUNT, G_HIST_WAVES, 1)]
void GlobalHistogram(int3 gtid : SV_GroupThreadID)
{
    //clear
    for (int i = GROUP_THREAD_ID; i < G_HIST_SHARED_MEM; i += G_HIST_THREADS)
        g_globalHist[i] = 0;
    GroupMemoryBarrierWithGroupSync();
    
    //histogram
    const uint t = G_HIST_W_G_START;
    for (int i = GROUP_THREAD_ID; i < e_size; i += G_HIST_THREADS)
    {
        const uint key = b_sort[i];
        InterlockedAdd(g_globalHist[(key & RADIX_MASK) + t].x, 1);
        InterlockedAdd(g_globalHist[(key >> SEC_RADIX & RADIX_MASK) + t].y, 1);
        InterlockedAdd(g_globalHist[(key >> THIRD_RADIX & RADIX_MASK) + t].z, 1);
        InterlockedAdd(g_globalHist[(key >> FOURTH_RADIX) + t].w, 1);

    }
    GroupMemoryBarrierWithGroupSync();
    
    //Reduce the wavegroups, this could be slightly better
    const uint t2 = LANE + ((WAVE_INDEX & 7) << LANE_LOG) + ((WAVE_INDEX >> 3) << 9);
    g_globalHist[t2] += g_globalHist[t2 + RADIX];
    GroupMemoryBarrierWithGroupSync();
    
    if (WAVE_INDEX > 7)
    {
        InterlockedAdd(g_globalHist[t2 & RADIX_MASK].x, g_globalHist[t2].x);
        InterlockedAdd(g_globalHist[t2 & RADIX_MASK].y, g_globalHist[t2].y);
        InterlockedAdd(g_globalHist[t2 & RADIX_MASK].z, g_globalHist[t2].z);
        InterlockedAdd(g_globalHist[t2 & RADIX_MASK].w, g_globalHist[t2].w);
    }
    GroupMemoryBarrierWithGroupSync();
    
    //Vectorized prefix sum
    if (WAVE_INDEX < (RADIX >> LANE_LOG))
        g_globalHist[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_globalHist[GROUP_THREAD_ID]) + g_globalHist[GROUP_THREAD_ID];
    GroupMemoryBarrierWithGroupSync();
    
    if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
        g_globalHist[LANE << LANE_LOG] += WavePrefixSum(g_globalHist[LANE << LANE_LOG]);
    GroupMemoryBarrierWithGroupSync();
    
    const uint t3 = GROUP_THREAD_ID & RADIX_MASK;
    b_globalHist[GROUP_THREAD_ID] = (LANE ? g_globalHist[t3][WAVE_INDEX >> 3] : 0) +
        (WAVE_INDEX & 7 ? WaveReadLaneAt(g_globalHist[t3 - LANE_COUNT][WAVE_INDEX >> 3], 0) : 0);
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void FirstBinningPass(int3 gtid : SV_GroupThreadID)
{
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID];
    GroupMemoryBarrierWithGroupSync();
    
    for (int partitionIndex = 0; partitionIndex < BIN_PARTITIONS; ++partitionIndex)
    {
        //clear
        {
            for (int i = LANE; i < RADIX; i += LANE_COUNT)
                g_waveHists[i + (WAVE_INDEX << RADIX_LOG)] = 0;
        }
        
        //read
        uint4 keys[BIN_KEY_VECS];
        {
            const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                keys[i].x = b_sort[t + (i << 7)];
                keys[i].y = b_sort[t + (i << 7) + 32];
                keys[i].z = b_sort[t + (i << 7) + 64];
                keys[i].w = b_sort[t + (i << 7) + 96];
            }
        }
        
        //Warp Level Multisplit
        uint4 offsets[BIN_KEY_VECS];
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                offsets[i] = 0xFFFFFFFF;

                [unroll]
                for (int k = 0; k < RADIX_LOG; ++k)
                {
                    const bool4 t = keys[i] >> k & 1;
                    offsets[i].x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
                    offsets[i].y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
                    offsets[i].z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
                    offsets[i].w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
                }
                
                const uint4 bits = countbits(offsets[i] << LANE_MASK - LANE);
                const uint t = (WAVE_INDEX << RADIX_LOG);
                
                [unroll]
                for (k = 0; k < VEC_SIZE; ++k)
                {
                    const int index = (keys[i][k] & RADIX_MASK) + t;
                    const uint prev = g_waveHists[index];
                    if (bits[k] == 1)
                        g_waveHists[index] += countbits(offsets[i][k]);
                    offsets[i][k] = prev + bits[k] - 1;
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms, store the reduction for later
        //serial per-thread significantly faster than per wave with intrinsics
        uint save;
        if (GROUP_THREAD_ID < RADIX)
        {
            const int t = GROUP_THREAD_ID;
            for (int k = t + RADIX; k < BIN_PART_SIZE; k += RADIX)
            {
                g_waveHists[t] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[t] - g_waveHists[k];
            }
            save = g_waveHists[t];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the reductions, decrement the running total histogram and store the value for later
        if (GROUP_THREAD_ID < RADIX)
            g_waveHists[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_waveHists[GROUP_THREAD_ID]) + g_waveHists[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_waveHists[LANE << LANE_LOG] = WavePrefixSum(g_waveHists[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX)
        {
            if (LANE)
                g_waveHists[GROUP_THREAD_ID] += WaveReadLaneAt(g_waveHists[GROUP_THREAD_ID - 1], 1);
            save += g_waveHists[GROUP_THREAD_ID];
            g_localHist[GROUP_THREAD_ID] -= g_waveHists[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    const uint t2 = keys[i][k] & RADIX_MASK;
                    offsets[i][k] += g_waveHists[t2 + t] + g_waveHists[t2];
                }
            }
        }
        else
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    offsets[i][k] += g_waveHists[keys[i][k] & RADIX_MASK];
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        {
            [unroll]
            for (int i = 0; i < VEC_SIZE; ++i)
            {
                g_waveHists[offsets[0][i]] = keys[0][i];
                g_waveHists[offsets[1][i]] = keys[1][i];
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        {
            for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
                b_alt[g_localHist[g_waveHists[i] & RADIX_MASK] + i] = g_waveHists[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update histogram
        if (GROUP_THREAD_ID < RADIX)
            g_localHist[GROUP_THREAD_ID] += save;
    }
    GroupMemoryBarrierWithGroupSync();
    
    for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
    {
        const uint key = b_sort[i];
        uint offset = 0xFFFFFFFF;
        
        [unroll]
        for (int k = 0; k < RADIX_LOG; ++k)
        {
            const bool t = key >> k & 1;
            offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
        }
        
        [unroll]
        for (int k = 0; k < BIN_WAVES; ++k)
        {
            if (WAVE_INDEX == k)
            {
                const uint t = g_localHist[key & RADIX_MASK];
                if (countbits(offset << LANE_MASK - LANE) == 1)
                    g_localHist[key & RADIX_MASK] += countbits(offset);
                offset = t + countbits((offset << LANE_MASK - LANE) << 1);
            }
            GroupMemoryBarrierWithGroupSync();
        }

        b_alt[offset] = key;
    }
    
    //for timing the execution of the kernel
    if (LANE == 0 && WAVE_INDEX == 0)
        b_timing[0] = 1;
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void SecBinningPass(int3 gtid : SV_GroupThreadID)
{
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + SEC_RADIX_START];
    GroupMemoryBarrierWithGroupSync();
    
    for (int partitionIndex = 0; partitionIndex < BIN_PARTITIONS; ++partitionIndex)
    {
        //clear
        {
            for (int i = LANE; i < RADIX; i += LANE_COUNT)
                g_waveHists[i + (WAVE_INDEX << RADIX_LOG)] = 0;
        }
        
        //read
        uint4 keys[BIN_KEY_VECS];
        {
            const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                keys[i].x = b_alt[t + (i << 7)];
                keys[i].y = b_alt[t + (i << 7) + 32];
                keys[i].z = b_alt[t + (i << 7) + 64];
                keys[i].w = b_alt[t + (i << 7) + 96];
            }
        }
        
        //Warp Level Multisplit
        uint4 offsets[BIN_KEY_VECS];
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                offsets[i] = 0xFFFFFFFF;

                [unroll]
                for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
                {
                    const bool4 t = keys[i] >> k & 1;
                    offsets[i].x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
                    offsets[i].y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
                    offsets[i].z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
                    offsets[i].w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
                }
                
                const uint4 bits = countbits(offsets[i] << LANE_MASK - LANE);
                const uint t = (WAVE_INDEX << RADIX_LOG);
                
                [unroll]
                for (k = 0; k < VEC_SIZE; ++k)
                {
                    const int index = (keys[i][k] >> SEC_RADIX & RADIX_MASK) + t;
                    const uint prev = g_waveHists[index];
                    if (bits[k] == 1)
                        g_waveHists[index] += countbits(offsets[i][k]);
                    offsets[i][k] = prev + bits[k] - 1;
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms, store the reduction for later
        //serial per-thread significantly faster than per wave with intrinsics
        uint save;
        if (GROUP_THREAD_ID < RADIX)
        {
            const int t = GROUP_THREAD_ID;
            for (int k = t + RADIX; k < BIN_PART_SIZE; k += RADIX)
            {
                g_waveHists[t] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[t] - g_waveHists[k];
            }
            save = g_waveHists[t];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the reductions, decrement the running total histogram and store the value for later
        if (GROUP_THREAD_ID < RADIX)
            g_waveHists[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_waveHists[GROUP_THREAD_ID]) + g_waveHists[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_waveHists[LANE << LANE_LOG] = WavePrefixSum(g_waveHists[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX)
        {
            if (LANE)
                g_waveHists[GROUP_THREAD_ID] += WaveReadLaneAt(g_waveHists[GROUP_THREAD_ID - 1], 1);
            save += g_waveHists[GROUP_THREAD_ID];
            g_localHist[GROUP_THREAD_ID] -= g_waveHists[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    const uint t2 = keys[i][k] >> SEC_RADIX & RADIX_MASK;
                    offsets[i][k] += g_waveHists[t2 + t] + g_waveHists[t2];
                }
            }
        }
        else
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    offsets[i][k] += g_waveHists[keys[i][k] >> SEC_RADIX & RADIX_MASK];
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        {
            [unroll]
            for (int i = 0; i < VEC_SIZE; ++i)
            {
                g_waveHists[offsets[0][i]] = keys[0][i];
                g_waveHists[offsets[1][i]] = keys[1][i];
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        {
            for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
                b_sort[g_localHist[g_waveHists[i] >> SEC_RADIX & RADIX_MASK] + i] = g_waveHists[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update histogram
        if (GROUP_THREAD_ID < RADIX)
            g_localHist[GROUP_THREAD_ID] += save;
    }
    GroupMemoryBarrierWithGroupSync();
    
    for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
    {
        const uint key = b_alt[i];
        uint offset = 0xFFFFFFFF;
        
        [unroll]
        for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
        {
            const bool t = key >> k & 1;
            offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
        }
        
        [unroll]
        for (int k = 0; k < BIN_WAVES; ++k)
        {
            if (WAVE_INDEX == k)
            {
                const uint t = g_localHist[key >> SEC_RADIX & RADIX_MASK];
                if (countbits(offset << LANE_MASK - LANE) == 1)
                    g_localHist[key >> SEC_RADIX & RADIX_MASK] += countbits(offset);
                offset = t + countbits((offset << LANE_MASK - LANE) << 1);
            }
            GroupMemoryBarrierWithGroupSync();
        }

        b_sort[offset] = key;
    }
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void ThirdBinningPass(int3 gtid : SV_GroupThreadID)
{
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + THIRD_RADIX_START];
    GroupMemoryBarrierWithGroupSync();
    
    for (int partitionIndex = 0; partitionIndex < BIN_PARTITIONS; ++partitionIndex)
    {
        //clear
        {
            for (int i = LANE; i < RADIX; i += LANE_COUNT)
                g_waveHists[i + (WAVE_INDEX << RADIX_LOG)] = 0;
        }
        
        //read
        uint4 keys[BIN_KEY_VECS];
        {
            const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                keys[i].x = b_sort[t + (i << 7)];
                keys[i].y = b_sort[t + (i << 7) + 32];
                keys[i].z = b_sort[t + (i << 7) + 64];
                keys[i].w = b_sort[t + (i << 7) + 96];
            }
        }
        
        //Warp Level Multisplit
        uint4 offsets[BIN_KEY_VECS];
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                offsets[i] = 0xFFFFFFFF;

                [unroll]
                for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
                {
                    const bool4 t = keys[i] >> k & 1;
                    offsets[i].x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
                    offsets[i].y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
                    offsets[i].z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
                    offsets[i].w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
                }
                
                const uint4 bits = countbits(offsets[i] << LANE_MASK - LANE);
                const uint t = (WAVE_INDEX << RADIX_LOG);
                
                [unroll]
                for (k = 0; k < VEC_SIZE; ++k)
                {
                    const int index = (keys[i][k] >> THIRD_RADIX & RADIX_MASK) + t;
                    const uint prev = g_waveHists[index];
                    if (bits[k] == 1)
                        g_waveHists[index] += countbits(offsets[i][k]);
                    offsets[i][k] = prev + bits[k] - 1;
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms, store the reduction for later
        //serial per-thread significantly faster than per wave with intrinsics
        uint save;
        if (GROUP_THREAD_ID < RADIX)
        {
            const int t = GROUP_THREAD_ID;
            for (int k = t + RADIX; k < BIN_PART_SIZE; k += RADIX)
            {
                g_waveHists[t] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[t] - g_waveHists[k];
            }
            save = g_waveHists[t];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the reductions, decrement the running total histogram and store the value for later
        if (GROUP_THREAD_ID < RADIX)
            g_waveHists[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_waveHists[GROUP_THREAD_ID]) + g_waveHists[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_waveHists[LANE << LANE_LOG] = WavePrefixSum(g_waveHists[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX)
        {
            if (LANE)
                g_waveHists[GROUP_THREAD_ID] += WaveReadLaneAt(g_waveHists[GROUP_THREAD_ID - 1], 1);
            save += g_waveHists[GROUP_THREAD_ID];
            g_localHist[GROUP_THREAD_ID] -= g_waveHists[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    const uint t2 = keys[i][k] >> THIRD_RADIX & RADIX_MASK;
                    offsets[i][k] += g_waveHists[t2 + t] + g_waveHists[t2];
                }
            }
        }
        else
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    offsets[i][k] += g_waveHists[keys[i][k] >> THIRD_RADIX & RADIX_MASK];
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        {
            [unroll]
            for (int i = 0; i < VEC_SIZE; ++i)
            {
                g_waveHists[offsets[0][i]] = keys[0][i];
                g_waveHists[offsets[1][i]] = keys[1][i];
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory
        {
            for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
                b_alt[g_localHist[g_waveHists[i] >> THIRD_RADIX & RADIX_MASK] + i] = g_waveHists[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update histogram
        if (GROUP_THREAD_ID < RADIX)
            g_localHist[GROUP_THREAD_ID] += save;
    }
    GroupMemoryBarrierWithGroupSync();
    
    for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
    {
        const uint key = b_sort[i];
        uint offset = 0xFFFFFFFF;
        
        [unroll]
        for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
        {
            const bool t = key >> k & 1;
            offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
        }
        
        [unroll]
        for (int k = 0; k < BIN_WAVES; ++k)
        {
            if (WAVE_INDEX == k)
            {
                const uint t = g_localHist[key >> THIRD_RADIX & RADIX_MASK];
                if (countbits(offset << LANE_MASK - LANE) == 1)
                    g_localHist[key >> THIRD_RADIX & RADIX_MASK] += countbits(offset);
                offset = t + countbits((offset << LANE_MASK - LANE) << 1);
            }
            GroupMemoryBarrierWithGroupSync();
        }

        b_alt[offset] = key;
    }
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void FourthBinningPass(int3 gtid : SV_GroupThreadID)
{
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + FOURTH_RADIX_START];
    GroupMemoryBarrierWithGroupSync();
    
    for (int partitionIndex = 0; partitionIndex < BIN_PARTITIONS; ++partitionIndex)
    {
        //clear
        {
            for (int i = LANE; i < RADIX; i += LANE_COUNT)
                g_waveHists[i + (WAVE_INDEX << RADIX_LOG)] = 0;
        }
        
        //read
        uint4 keys[BIN_KEY_VECS];
        {
            const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                keys[i].x = b_alt[t + (i << 7)];
                keys[i].y = b_alt[t + (i << 7) + 32];
                keys[i].z = b_alt[t + (i << 7) + 64];
                keys[i].w = b_alt[t + (i << 7) + 96];
            }
        }
        
        //Warp Level Multisplit
        uint4 offsets[BIN_KEY_VECS];
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                offsets[i] = 0xFFFFFFFF;

                [unroll]
                for (int k = FOURTH_RADIX; k < 32; ++k)
                {
                    const bool4 t = keys[i] >> k & 1;
                    offsets[i].x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
                    offsets[i].y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
                    offsets[i].z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
                    offsets[i].w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
                }
                
                const uint4 bits = countbits(offsets[i] << LANE_MASK - LANE);
                const uint t = (WAVE_INDEX << RADIX_LOG);
                
                [unroll]
                for (k = 0; k < VEC_SIZE; ++k)
                {
                    const int index = (keys[i][k] >> FOURTH_RADIX) + t;
                    const uint prev = g_waveHists[index];
                    if (bits[k] == 1)
                        g_waveHists[index] += countbits(offsets[i][k]);
                    offsets[i][k] = prev + bits[k] - 1;
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms, store the reduction for later
        //serial per-thread significantly faster than per wave with intrinsics
        uint save;
        if (GROUP_THREAD_ID < RADIX)
        {
            const int t = GROUP_THREAD_ID;
            for (int k = t + RADIX; k < BIN_PART_SIZE; k += RADIX)
            {
                g_waveHists[t] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[t] - g_waveHists[k];
            }
            save = g_waveHists[t];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the reductions, decrement the running total histogram and store the value for later
        if (GROUP_THREAD_ID < RADIX)
            g_waveHists[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_waveHists[GROUP_THREAD_ID]) + g_waveHists[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_waveHists[LANE << LANE_LOG] = WavePrefixSum(g_waveHists[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX)
        {
            if (LANE)
                g_waveHists[GROUP_THREAD_ID] += WaveReadLaneAt(g_waveHists[GROUP_THREAD_ID - 1], 1);
            save += g_waveHists[GROUP_THREAD_ID];
            g_localHist[GROUP_THREAD_ID] -= g_waveHists[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    const uint t2 = keys[i][k] >> FOURTH_RADIX;
                    offsets[i][k] += g_waveHists[t2 + t] + g_waveHists[t2];
                }
            }
        }
        else
        {
            [unroll]
            for (int i = 0; i < BIN_KEY_VECS; ++i)
            {
                [unroll]
                for (int k = 0; k < VEC_SIZE; ++k)
                {
                    offsets[i][k] += g_waveHists[keys[i][k] >> FOURTH_RADIX];
                }
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        {
            [unroll]
            for (int i = 0; i < VEC_SIZE; ++i)
            {
                g_waveHists[offsets[0][i]] = keys[0][i];
                g_waveHists[offsets[1][i]] = keys[1][i];
            }
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        {
            for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
                b_sort[g_localHist[g_waveHists[i] >> FOURTH_RADIX] + i] = g_waveHists[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Update histogram
        if (GROUP_THREAD_ID < RADIX)
            g_localHist[GROUP_THREAD_ID] += save;
    }
    GroupMemoryBarrierWithGroupSync();
    
    for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
    {
        const uint key = b_alt[i];
        uint offset = 0xFFFFFFFF;
        
        [unroll]
        for (int k = FOURTH_RADIX; k < 32; ++k)
        {
            const bool t = key >> k & 1;
            offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
        }
        
        [unroll]
        for (int k = 0; k < BIN_WAVES; ++k)
        {
            if (WAVE_INDEX == k)
            {
                const uint t = g_localHist[key >> FOURTH_RADIX];
                if (countbits(offset << LANE_MASK - LANE) == 1)
                    g_localHist[key >> FOURTH_RADIX] += countbits(offset);
                offset = t + countbits((offset << LANE_MASK - LANE) << 1);
            }
            GroupMemoryBarrierWithGroupSync();
        }

        b_sort[offset] = key;
    }
    
    //for timing the execution of the kernel
    if (LANE == 0 && WAVE_INDEX == 0)
        b_timing[0] = 1;
}