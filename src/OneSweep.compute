/******************************************************************************
 * OneSweep
 * 
 * Author:  Thomas Smith 8/15/2023
 *
 * Based off of Research by:
 *          Andy Adinets, Nvidia Corporation
 *          Duane Merrill, Nvidia Corporation
 *          https://research.nvidia.com/publication/2022-06_onesweep-faster-least-significant-digit-radix-sort-gpus
 *
 * Copyright (c) 2011, Duane Merrill.  All rights reserved.
 * Copyright (c) 2011-2023, NVIDIA CORPORATION.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the
 *       names of its contributors may be used to endorse or promote products
 *       derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 ******************************************************************************/
#pragma use_dxc
#pragma kernel Init
#pragma kernel InitRandom
#pragma kernel GlobalHistogram 
#pragma kernel FirstBinningPass
#pragma kernel SecBinningPass
#pragma kernel ThirdBinningPass
#pragma kernel FourthBinningPass

//General macros 
#define LANE_COUNT          32      //Lane count in wave, Nvidia hardware
#define LANE_MASK           31      //Mask of the lane count
#define LANE_LOG            5       //log2(LANE_COUNT)

#define RADIX               256     //Number of digit bins
#define RADIX_MASK          255     //Mask of digit bins
#define RADIX_LOG           8       //log2(RADIX)
#define SEC_RADIX           8       //Shift value to retrieve digits from the second place
#define THIRD_RADIX         16      //Shift value to retrieve digits from the third place
#define FOURTH_RADIX        24      //Shift value to retrieve digits from the fourth place 
#define SEC_RADIX_START     256     //Offset for retrieving values from global buffer
#define THIRD_RADIX_START   512     //Offset for retrieving values from global buffer
#define FOURTH_RADIX_START  768     //Offset for retrieving values from global buffer

#define LANE                gtid.x                                  //The lane of a thread
#define WAVE_INDEX          gtid.y                                  //The wave of a thread
#define GROUP_THREAD_ID     (LANE + (WAVE_INDEX << LANE_LOG))       //The group relative thread id

//For the upfront global histogram kernel
#define G_HIST_WAVES        2                                       //The number of waves in a GlobalHistogram threadblock
#define G_HIST_THREADS      64                                      //The number of threads in a GlobalHistogram threadblock
#define G_HIST_TBLOCKS      2048                                    //The number of threadblocks dispatched for the GlobalHistogram kernel
#define G_HIST_PART_SIZE    (e_size / G_HIST_TBLOCKS)               //The partition tile size of a GlobalHistogram threadblock
#define G_HIST_PART_START   (gid.x * G_HIST_PART_SIZE)              //The starting offset of a partition tile
#define G_HIST_PART_END     (gid.x == G_HIST_TBLOCKS - 1 ? \
                            e_size : (gid.x + 1) * G_HIST_PART_SIZE)

//For the binning
#define BIN_PART_SIZE       7680    //The partition tile size of a BinningPass threadblock
#define BIN_HISTS_SIZE      4096    //The total size of all wave histograms in shared memory
#define BIN_TBLOCKS         512     //The number of threadblocks dispatched in a BinningPass threadblock
#define BIN_THREADS         512     //The number of threads in a BinningPass threadblock
#define BIN_SUB_PART_SIZE   480     //The subpartition tile size of a single wave in a BinningPass threadblock
#define BIN_WAVES           16      //The number of waves in a BinningPass threadblock

#define FLAG_NOT_READY      0       //Flag value inidicating neither inclusive sum, or aggregate sum of a partition tile is ready
#define FLAG_AGGREGATE      1       //Flag value indicating aggregate sum of a partition tile is ready
#define FLAG_INCLUSIVE      2       //Flag value indicating inclusive sum of a partition tile is ready
#define FLAG_MASK           3       //Mask used to retrieve flag values

#define BIN_PARTITIONS     (e_size / BIN_PART_SIZE)             //The number of partition tiles in a BinningPass
#define BIN_SUB_PART_START (WAVE_INDEX * BIN_SUB_PART_SIZE)     //The starting offset of a subpartition tile
#define BIN_PART_START     (partitionIndex * BIN_PART_SIZE)     //The starting offset of a partition tile

//Hybrid LCG-Tausworthe PRNG
//From GPU GEMS 3, Chapter 37
//Authors: Lee Howes and David Thomas 
#define TAUS_STEP_1         ((z1 & 4294967294U) << 12) ^ (((z1 << 13) ^ z1) >> 19)
#define TAUS_STEP_2         ((z2 & 4294967288U) << 4) ^ (((z2 << 2) ^ z2) >> 25)
#define TAUS_STEP_3         ((z3 & 4294967280U) << 17) ^ (((z3 << 3) ^ z3) >> 11)
#define LCG_STEP            (z4 * 1664525 + 1013904223U)
#define HYBRID_TAUS         ((z1 ^ z2 ^ z3 ^ z4) & 268435455)

extern int e_size;                              //Input size, passed in from CPU
extern uint e_seed;                             //Seed for PRNGS, passed in from CPU

RWBuffer<uint> b_sort;                          //buffer to be sorted
RWBuffer<uint> b_alt;                           //double buffer
RWBuffer<uint> b_globalHist;                    //buffer holding device level offsets for each binning pass
RWBuffer<uint> b_timing;                        //To time the execution of the kernels

globallycoherent RWBuffer<uint> b_index;        //buffer used to atomically assign partition tiles to threadblocks, see Chained Scan with Decoupled Lookback repo, Deadlocking section
globallycoherent RWBuffer<uint> b_passHist;     //buffer use to store reduced sums of partition tiles
globallycoherent RWBuffer<uint> b_passTwo;      //buffer use to store reduced sums of partition tiles
globallycoherent RWBuffer<uint> b_passThree;    //buffer use to store reduced sums of partition tiles
globallycoherent RWBuffer<uint> b_passFour;     //buffer use to store reduced sums of partition tiles

groupshared uint4 g_globalHist[RADIX];          //Shared memory for performing the upfront global histogram
groupshared uint g_localHist[RADIX];            //Threadgroup copy of globalHist during digit binning passes
groupshared uint g_waveHists[BIN_PART_SIZE];    //Shared memory for the per wave histograms during digit binning passes
groupshared uint g_reductionHist[RADIX];        //Shared memory for reduced per wave histograms during digit binning pass

[numthreads(1024, 1, 1)]
void Init(int3 id : SV_DispatchThreadID)
{
    for (int i = id.x; i < e_size; i += 1024 * 256)
        b_sort[i] = e_size - i;
    
    if (id.x < 1024)
        b_globalHist[id.x] = 0;
        
    if (id.x < 4)
        b_index[id.x] = 0;

    const int size = BIN_PARTITIONS << RADIX_LOG;
    const int t = 1024 * 256;
    for (int i = id.x; i < size; i += t)
    {
        b_passHist[i] = 0;
        b_passTwo[i] = 0;
        b_passThree[i] = 0;
        b_passFour[i] = 0;
    }
}

[numthreads(1024, 1, 1)]
void InitRandom(int3 id : SV_DispatchThreadID)
{
    uint z1 = (id.x << 2) * e_seed;
    uint z2 = ((id.x << 2) + 1) * e_seed;
    uint z3 = ((id.x << 2) + 2) * e_seed;
    uint z4 = ((id.x << 2) + 3) * e_seed;
    
    for (int i = id.x; i < e_size; i += 1024 * 256)
    {
        z1 = TAUS_STEP_1;
        z2 = TAUS_STEP_2;
        z3 = TAUS_STEP_3;
        z4 = LCG_STEP;
        b_sort[i] = HYBRID_TAUS;
    }
    
    if (id.x < 1024)
        b_globalHist[id.x] = 0;
    
    if (id.x < 4)
        b_index[id.x] = 0;

    const int size = BIN_PARTITIONS << RADIX_LOG;
    const int t = 1024 * 256;
    for (int i = id.x; i < size; i += t)
    {
        b_passHist[i] = 0;
        b_passTwo[i] = 0;
        b_passThree[i] = 0;
        b_passFour[i] = 0;
    }
}

[numthreads(LANE_COUNT, G_HIST_WAVES, 1)]
void GlobalHistogram(int3 gtid : SV_GroupThreadID, int3 gid : SV_GroupID)
{
    for (int i = GROUP_THREAD_ID; i < RADIX; i += G_HIST_THREADS)
        g_globalHist[i] = 0;
    GroupMemoryBarrierWithGroupSync();

    //histogram
    const int partitionEnd = G_HIST_PART_END;
    for (int i = GROUP_THREAD_ID + G_HIST_PART_START; i < partitionEnd; i += G_HIST_THREADS)
    {
        const uint key = b_sort[i];
        InterlockedAdd(g_globalHist[key & RADIX_MASK].x, 1);
        InterlockedAdd(g_globalHist[key >> SEC_RADIX & RADIX_MASK].y, 1);
        InterlockedAdd(g_globalHist[key >> THIRD_RADIX & RADIX_MASK].z, 1);
        InterlockedAdd(g_globalHist[key >> FOURTH_RADIX].w, 1);
    }
    GroupMemoryBarrierWithGroupSync();
    
    //prefixsum
    for(int i = WAVE_INDEX << LANE_LOG; i < RADIX; i += G_HIST_THREADS)
        g_globalHist[(LANE + 1 & LANE_MASK) + i] = WavePrefixSum(g_globalHist[LANE + i]) + g_globalHist[LANE + i];
    GroupMemoryBarrierWithGroupSync();
    
    if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
        g_globalHist[LANE << LANE_LOG] += WavePrefixSum(g_globalHist[LANE << LANE_LOG]);
    GroupMemoryBarrierWithGroupSync();
    
    int k = GROUP_THREAD_ID;
    InterlockedAdd(b_globalHist[k], (LANE ? g_globalHist[k].x : 0) + (WAVE_INDEX ? WaveReadLaneAt(g_globalHist[k - LANE_COUNT].x, 0) : 0));
    InterlockedAdd(b_globalHist[k + SEC_RADIX_START], (LANE ? g_globalHist[k].y : 0) + (WAVE_INDEX ? WaveReadLaneAt(g_globalHist[k - LANE_COUNT].y, 0) : 0));
    InterlockedAdd(b_globalHist[k + THIRD_RADIX_START], (LANE ? g_globalHist[k].z : 0) + (WAVE_INDEX ? WaveReadLaneAt(g_globalHist[k - LANE_COUNT].z, 0) : 0));
    InterlockedAdd(b_globalHist[k + FOURTH_RADIX_START], (LANE ? g_globalHist[k].w : 0) + (WAVE_INDEX ? WaveReadLaneAt(g_globalHist[k - LANE_COUNT].w, 0) : 0));
    
    for (k += G_HIST_THREADS; k < RADIX; k += G_HIST_THREADS)
    {
        InterlockedAdd(b_globalHist[k], (LANE ? g_globalHist[k].x : 0) + WaveReadLaneAt(g_globalHist[k - LANE_COUNT].x, 0));
        InterlockedAdd(b_globalHist[k + SEC_RADIX_START], (LANE ? g_globalHist[k].y : 0) + WaveReadLaneAt(g_globalHist[k - LANE_COUNT].y, 0));
        InterlockedAdd(b_globalHist[k + THIRD_RADIX_START], (LANE ? g_globalHist[k].z : 0) + WaveReadLaneAt(g_globalHist[k - LANE_COUNT].z, 0));
        InterlockedAdd(b_globalHist[k + FOURTH_RADIX_START], (LANE ? g_globalHist[k].w : 0) + WaveReadLaneAt(g_globalHist[k - LANE_COUNT].w, 0));
    }
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void FirstBinningPass(int3 gtid : SV_GroupThreadID)
{
    //load the global histogram values into shared memory
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID];
    
    int partitionIndex;
    do
    {
        //atomically fetch and increment device memory index to assign partition tiles
        //Take advantage of the barrier to also clear the shared memory
        if(LANE == 0 && WAVE_INDEX == 0)
            InterlockedAdd(b_index[0], 1, g_localHist[0]);
        GroupMemoryBarrierWithGroupSync();
        partitionIndex = WaveReadLaneAt(g_localHist[0], 0);
        for (int i = GROUP_THREAD_ID; i < BIN_HISTS_SIZE; i += BIN_THREADS)
            g_waveHists[i] = 0;
        GroupMemoryBarrierWithGroupSync();
        if (partitionIndex >= BIN_PARTITIONS)
            break;
        
        //Load keys into registers
        const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
        uint4 firstKeys;
        firstKeys.x = b_sort[t];
        firstKeys.y = b_sort[t + 32];
        firstKeys.z = b_sort[t + 64];
        firstKeys.w = b_sort[t + 96];
        
        uint4 secKeys;
        secKeys.x = b_sort[t + 128];
        secKeys.y = b_sort[t + 160];
        secKeys.z = b_sort[t + 192];
        secKeys.w = b_sort[t + 224];
        
        uint4 thirdKeys;
        thirdKeys.x = b_sort[t + 256];
        thirdKeys.y = b_sort[t + 288];
        thirdKeys.z = b_sort[t + 320];
        thirdKeys.w = b_sort[t + 352];
        
        uint3 fourthKeys;
        fourthKeys.x = b_sort[t + 384];
        fourthKeys.y = b_sort[t + 416];
        fourthKeys.z = b_sort[t + 448];

        //Warp Level Multisplit, manually unrolled
        uint4 firstOffsets = 0xFFFFFFFF;
        for (int k = 0; k < RADIX_LOG; ++k)
        {
            const bool4 t = firstKeys >> k & 1;
            firstOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            firstOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            firstOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            firstOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        uint4 bits = countbits(firstOffsets << LANE_MASK - LANE);
        int index = (firstKeys.x & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        uint prev = g_waveHists[index];
        if(bits.x == 1)
            g_waveHists[index] += countbits(firstOffsets.x);
        firstOffsets.x = prev + bits.x - 1;
        
        index = (firstKeys.y & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(firstOffsets.y);
        firstOffsets.y = prev + bits.y - 1;
        
        index = (firstKeys.z & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(firstOffsets.z);
        firstOffsets.z = prev + bits.z - 1;
        
        index = (firstKeys.w & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(firstOffsets.w);
        firstOffsets.w = prev + bits.w - 1;
        
        //Second
        uint4 secOffsets = 0xFFFFFFFF;
        for (int k = 0; k < RADIX_LOG; ++k)
        {
            const bool4 t = secKeys >> k & 1;
            secOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            secOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            secOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            secOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(secOffsets << LANE_MASK - LANE);
        index = (secKeys.x & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(secOffsets.x);
        secOffsets.x = prev + bits.x - 1;
        
        index = (secKeys.y & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(secOffsets.y);
        secOffsets.y = prev + bits.y - 1;
        
        index = (secKeys.z & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(secOffsets.z);
        secOffsets.z = prev + bits.z - 1;
        
        index = (secKeys.w & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(secOffsets.w);
        secOffsets.w = prev + bits.w - 1;
        
        //Third
        uint4 thirdOffsets = 0xFFFFFFFF;
        for (int k = 0; k < RADIX_LOG; ++k)
        {
            const bool4 t = thirdKeys >> k & 1;
            thirdOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            thirdOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            thirdOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            thirdOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(thirdOffsets << LANE_MASK - LANE);
        index = (thirdKeys.x & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(thirdOffsets.x);
        thirdOffsets.x = prev + bits.x - 1;
        
        index = (thirdKeys.y & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(thirdOffsets.y);
        thirdOffsets.y = prev + bits.y - 1;
        
        index = (thirdKeys.z & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(thirdOffsets.z);
        thirdOffsets.z = prev + bits.z - 1;
        
        index = (thirdKeys.w & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(thirdOffsets.w);
        thirdOffsets.w = prev + bits.w - 1;
        
        uint3 fourthOffsets = 0xFFFFFFFF;
        for (int k = 0; k < RADIX_LOG; ++k)
        {
            const bool3 t = fourthKeys >> k & 1;
            fourthOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            fourthOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            fourthOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
        }
        
        bits.x = countbits(fourthOffsets.x << LANE_MASK - LANE);
        bits.y = countbits(fourthOffsets.y << LANE_MASK - LANE);
        bits.z = countbits(fourthOffsets.z << LANE_MASK - LANE);
        index = (fourthKeys.x & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(fourthOffsets.x);
        fourthOffsets.x = prev + bits.x - 1;
        
        index = (fourthKeys.y & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(fourthOffsets.y);
        fourthOffsets.y = prev + bits.y - 1;
        
        index = (fourthKeys.z & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(fourthOffsets.z);
        fourthOffsets.z = prev + bits.z - 1;
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms
        if (GROUP_THREAD_ID < RADIX)
        {
            for (int k = GROUP_THREAD_ID + RADIX; k < BIN_HISTS_SIZE; k += RADIX)
            {
                g_waveHists[GROUP_THREAD_ID] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[GROUP_THREAD_ID] - g_waveHists[k];
            }
            g_reductionHist[GROUP_THREAD_ID] = g_waveHists[GROUP_THREAD_ID];
            
            if (partitionIndex == 0)
                InterlockedAdd(b_passHist[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_INCLUSIVE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
            else
                InterlockedAdd(b_passHist[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_AGGREGATE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
        }
        GroupMemoryBarrierWithGroupSync(); // a barrier must be placed between here and the lookback to prevent accidentally broadcasting an incorrect aggregate

        //exclusive prefix sum across the reductions
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_reductionHist[GROUP_THREAD_ID]) + g_reductionHist[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_reductionHist[LANE << LANE_LOG] = WavePrefixSum(g_reductionHist[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if(GROUP_THREAD_ID < RADIX && LANE)
            g_reductionHist[GROUP_THREAD_ID] += WaveReadLaneAt(g_reductionHist[GROUP_THREAD_ID - 1], 1); //check this later
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            firstOffsets.x += g_waveHists[(firstKeys.x & RADIX_MASK) + t] + g_reductionHist[firstKeys.x & RADIX_MASK];
            firstOffsets.y += g_waveHists[(firstKeys.y & RADIX_MASK) + t] + g_reductionHist[firstKeys.y & RADIX_MASK];
            firstOffsets.z += g_waveHists[(firstKeys.z & RADIX_MASK) + t] + g_reductionHist[firstKeys.z & RADIX_MASK];
            firstOffsets.w += g_waveHists[(firstKeys.w & RADIX_MASK) + t] + g_reductionHist[firstKeys.w & RADIX_MASK];

            secOffsets.x += g_waveHists[(secKeys.x & RADIX_MASK) + t] + g_reductionHist[secKeys.x & RADIX_MASK];
            secOffsets.y += g_waveHists[(secKeys.y & RADIX_MASK) + t] + g_reductionHist[secKeys.y & RADIX_MASK];
            secOffsets.z += g_waveHists[(secKeys.z & RADIX_MASK) + t] + g_reductionHist[secKeys.z & RADIX_MASK];
            secOffsets.w += g_waveHists[(secKeys.w & RADIX_MASK) + t] + g_reductionHist[secKeys.w & RADIX_MASK];
            
            thirdOffsets.x += g_waveHists[(thirdKeys.x & RADIX_MASK) + t] + g_reductionHist[thirdKeys.x & RADIX_MASK];
            thirdOffsets.y += g_waveHists[(thirdKeys.y & RADIX_MASK) + t] + g_reductionHist[thirdKeys.y & RADIX_MASK];
            thirdOffsets.z += g_waveHists[(thirdKeys.z & RADIX_MASK) + t] + g_reductionHist[thirdKeys.z & RADIX_MASK];
            thirdOffsets.w += g_waveHists[(thirdKeys.w & RADIX_MASK) + t] + g_reductionHist[thirdKeys.w & RADIX_MASK];
            
            fourthOffsets.x += g_waveHists[(fourthKeys.x & RADIX_MASK) + t] + g_reductionHist[fourthKeys.x & RADIX_MASK];
            fourthOffsets.y += g_waveHists[(fourthKeys.y & RADIX_MASK) + t] + g_reductionHist[fourthKeys.y & RADIX_MASK];
            fourthOffsets.z += g_waveHists[(fourthKeys.z & RADIX_MASK) + t] + g_reductionHist[fourthKeys.z & RADIX_MASK];
        }
        else
        {
            firstOffsets.x += g_reductionHist[firstKeys.x & RADIX_MASK];
            firstOffsets.y += g_reductionHist[firstKeys.y & RADIX_MASK];
            firstOffsets.z += g_reductionHist[firstKeys.z & RADIX_MASK];
            firstOffsets.w += g_reductionHist[firstKeys.w & RADIX_MASK];

            secOffsets.x += g_reductionHist[secKeys.x & RADIX_MASK];
            secOffsets.y += g_reductionHist[secKeys.y & RADIX_MASK];
            secOffsets.z += g_reductionHist[secKeys.z & RADIX_MASK];
            secOffsets.w += g_reductionHist[secKeys.w & RADIX_MASK];
            
            thirdOffsets.x += g_reductionHist[thirdKeys.x & RADIX_MASK];
            thirdOffsets.y += g_reductionHist[thirdKeys.y & RADIX_MASK];
            thirdOffsets.z += g_reductionHist[thirdKeys.z & RADIX_MASK];
            thirdOffsets.w += g_reductionHist[thirdKeys.w & RADIX_MASK];
            
            fourthOffsets.x += g_reductionHist[fourthKeys.x & RADIX_MASK];
            fourthOffsets.y += g_reductionHist[fourthKeys.y & RADIX_MASK];
            fourthOffsets.z += g_reductionHist[fourthKeys.z & RADIX_MASK];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        //For some bizarre reason, this is signicantly faster rolled 
        for (int i = 0; i < 4; ++i)
        {
            g_waveHists[firstOffsets[i]] = firstKeys[i];
            g_waveHists[secOffsets[i]] = secKeys[i];
            g_waveHists[thirdOffsets[i]] = thirdKeys[i];
            if(i < 3)
                g_waveHists[fourthOffsets[i]] = fourthKeys[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Lookback
        if (partitionIndex)
        {
            //Free up shared memory, because we are at max
            const uint t = g_waveHists[WAVE_INDEX];
            
            for (int i = WAVE_INDEX; i < RADIX; i += BIN_WAVES)
            {
                uint aggregate = 0;
                if (LANE == 0)
                    g_waveHists[WAVE_INDEX] = partitionIndex;
                
                for (int k = partitionIndex - LANE - 1; 0 <= k; )
                {
                    uint flagPayload = b_passHist[i * BIN_PARTITIONS + k];
                    if (WaveActiveAllTrue((flagPayload & FLAG_MASK) > FLAG_NOT_READY))
                    {
                        if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE)
                        {
                            if (WaveIsFirstLane())
                                g_waveHists[WAVE_INDEX] = k;
                        }
                        
                        if (g_waveHists[WAVE_INDEX] < partitionIndex)
                        {
                            aggregate += WaveActiveSum(k >= g_waveHists[WAVE_INDEX] ? (flagPayload >> 2) : 0);
                                
                            if (LANE == 0)
                            {
                                InterlockedAdd(b_passHist[i * BIN_PARTITIONS + partitionIndex], 1 ^ (aggregate << 2));
                                g_reductionHist[i] = aggregate + (i ? g_localHist[i] : 0) - g_reductionHist[i];
                            }
                            break;
                        }
                        else
                        {
                            aggregate += WaveActiveSum(flagPayload >> 2);
                            k -= LANE_COUNT;
                        }
                    }
                }
            }
            
            //place value back
            if (LANE == 0)
                g_waveHists[WAVE_INDEX] = t;
        }
        else
        {
            if(GROUP_THREAD_ID < RADIX)
                g_reductionHist[GROUP_THREAD_ID] = (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0) - g_reductionHist[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
        {
            firstKeys.x = g_waveHists[i];
            firstKeys.y = firstKeys.x & RADIX_MASK;
            firstKeys.z = g_reductionHist[firstKeys.y] + i;
            b_alt[firstKeys.z] = firstKeys.x;
        }
    } while (partitionIndex + BIN_TBLOCKS < BIN_PARTITIONS);
    
    //for input sizes which are not perfect multiples of the partition tile size
    if (partitionIndex == BIN_PARTITIONS - 1)
    {
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[GROUP_THREAD_ID] = (b_passHist[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex] >> 2) + (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0);
        GroupMemoryBarrierWithGroupSync();
        
        partitionIndex++;
        for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
        {
            const uint key = b_sort[i];
        
            uint offset = 0xFFFFFFFF;
            for (int k = 0; k < RADIX_LOG; ++k)
            {
                const bool t = key >> k & 1;
                offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
            }
        
            for (int k = 0; k < BIN_WAVES; ++k)
            {
                if (WAVE_INDEX == k)
                {
                    const uint t = g_reductionHist[key & RADIX_MASK];
                    if (countbits(offset << LANE_MASK - LANE) == 1)
                        g_reductionHist[key & RADIX_MASK] += countbits(offset);
                    offset = t + countbits((offset << LANE_MASK - LANE) << 1);
                }
                GroupMemoryBarrierWithGroupSync();
            }

            b_alt[offset] = key;
        }
    }
    //for the single pass timing test
    if (LANE == 0 && WAVE_INDEX == 0)
        b_timing[0] = 1;
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void SecBinningPass(int3 gtid : SV_GroupThreadID)
{
    //load the global histogram values into shared memory
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + SEC_RADIX_START];
    
    int partitionIndex;
    do
    {
        //atomically fetch and increment device memory index to assign partition tiles
        //Take advantage of the barrier to also clear the shared memory
        if (LANE == 0 && WAVE_INDEX == 0)
            InterlockedAdd(b_index[1], 1, g_localHist[0]);
        GroupMemoryBarrierWithGroupSync();
        partitionIndex = WaveReadLaneAt(g_localHist[0], 0);
        for (int i = GROUP_THREAD_ID; i < BIN_HISTS_SIZE; i += BIN_THREADS)
            g_waveHists[i] = 0;
        GroupMemoryBarrierWithGroupSync();
        if (partitionIndex >= BIN_PARTITIONS)
            break;
        
        //Load keys into registers
        const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
        uint4 firstKeys;
        firstKeys.x = b_alt[t];
        firstKeys.y = b_alt[t + 32];
        firstKeys.z = b_alt[t + 64];
        firstKeys.w = b_alt[t + 96];
        
        uint4 secKeys;
        secKeys.x = b_alt[t + 128];
        secKeys.y = b_alt[t + 160];
        secKeys.z = b_alt[t + 192];
        secKeys.w = b_alt[t + 224];
        
        uint4 thirdKeys;
        thirdKeys.x = b_alt[t + 256];
        thirdKeys.y = b_alt[t + 288];
        thirdKeys.z = b_alt[t + 320];
        thirdKeys.w = b_alt[t + 352];
        
        uint3 fourthKeys;
        fourthKeys.x = b_alt[t + 384];
        fourthKeys.y = b_alt[t + 416];
        fourthKeys.z = b_alt[t + 448];
        
        //Warp Level Multisplit, manually unrolled
        uint4 firstOffsets = 0xFFFFFFFF;
        for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
        {
            const bool4 t = firstKeys >> k & 1;
            firstOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            firstOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            firstOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            firstOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        uint4 bits = countbits(firstOffsets << LANE_MASK - LANE);
        int index = (firstKeys.x >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        uint prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(firstOffsets.x);
        firstOffsets.x = prev + bits.x - 1;
        
        index = (firstKeys.y >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(firstOffsets.y);
        firstOffsets.y = prev + bits.y - 1;
        
        index = (firstKeys.z >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(firstOffsets.z);
        firstOffsets.z = prev + bits.z - 1;
        
        index = (firstKeys.w >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(firstOffsets.w);
        firstOffsets.w = prev + bits.w - 1;
        
        //Second
        uint4 secOffsets = 0xFFFFFFFF;
        for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
        {
            const bool4 t = secKeys >> k & 1;
            secOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            secOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            secOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            secOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(secOffsets << LANE_MASK - LANE);
        index = (secKeys.x >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(secOffsets.x);
        secOffsets.x = prev + bits.x - 1;
        
        index = (secKeys.y >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(secOffsets.y);
        secOffsets.y = prev + bits.y - 1;
        
        index = (secKeys.z >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(secOffsets.z);
        secOffsets.z = prev + bits.z - 1;
        
        index = (secKeys.w >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(secOffsets.w);
        secOffsets.w = prev + bits.w - 1;
        
        //Third
        uint4 thirdOffsets = 0xFFFFFFFF;
        for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
        {
            const bool4 t = thirdKeys >> k & 1;
            thirdOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            thirdOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            thirdOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            thirdOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(thirdOffsets << LANE_MASK - LANE);
        index = (thirdKeys.x >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(thirdOffsets.x);
        thirdOffsets.x = prev + bits.x - 1;
        
        index = (thirdKeys.y >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(thirdOffsets.y);
        thirdOffsets.y = prev + bits.y - 1;
        
        index = (thirdKeys.z >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(thirdOffsets.z);
        thirdOffsets.z = prev + bits.z - 1;
        
        index = (thirdKeys.w >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(thirdOffsets.w);
        thirdOffsets.w = prev + bits.w - 1;
        
        uint3 fourthOffsets = 0xFFFFFFFF;
        for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
        {
            const bool3 t = fourthKeys >> k & 1;
            fourthOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            fourthOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            fourthOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
        }
        
        bits.x = countbits(fourthOffsets.x << LANE_MASK - LANE);
        bits.y = countbits(fourthOffsets.y << LANE_MASK - LANE);
        bits.z = countbits(fourthOffsets.z << LANE_MASK - LANE);
        index = (fourthKeys.x >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(fourthOffsets.x);
        fourthOffsets.x = prev + bits.x - 1;
        
        index = (fourthKeys.y >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(fourthOffsets.y);
        fourthOffsets.y = prev + bits.y - 1;
        
        index = (fourthKeys.z >> SEC_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(fourthOffsets.z);
        fourthOffsets.z = prev + bits.z - 1;
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms
        if (GROUP_THREAD_ID < RADIX)
        {
            for (int k = GROUP_THREAD_ID + RADIX; k < BIN_HISTS_SIZE; k += RADIX)
            {
                g_waveHists[GROUP_THREAD_ID] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[GROUP_THREAD_ID] - g_waveHists[k];
            }
            g_reductionHist[GROUP_THREAD_ID] = g_waveHists[GROUP_THREAD_ID];
            
            if (partitionIndex == 0)
                InterlockedAdd(b_passTwo[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_INCLUSIVE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
            else
                InterlockedAdd(b_passTwo[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_AGGREGATE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
        }
        GroupMemoryBarrierWithGroupSync(); // a barrier must be placed between here and the lookback to prevent accidentally broadcasting an incorrect aggregate

        //exclusive prefix sum across the reductions
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_reductionHist[GROUP_THREAD_ID]) + g_reductionHist[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_reductionHist[LANE << LANE_LOG] = WavePrefixSum(g_reductionHist[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX && LANE)
            g_reductionHist[GROUP_THREAD_ID] += WaveReadLaneAt(g_reductionHist[GROUP_THREAD_ID - 1], 1); //check this later
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            firstOffsets.x += g_waveHists[(firstKeys.x >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.x >> SEC_RADIX & RADIX_MASK];
            firstOffsets.y += g_waveHists[(firstKeys.y >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.y >> SEC_RADIX & RADIX_MASK];
            firstOffsets.z += g_waveHists[(firstKeys.z >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.z >> SEC_RADIX & RADIX_MASK];
            firstOffsets.w += g_waveHists[(firstKeys.w >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.w >> SEC_RADIX & RADIX_MASK];

            secOffsets.x += g_waveHists[(secKeys.x >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.x >> SEC_RADIX & RADIX_MASK];
            secOffsets.y += g_waveHists[(secKeys.y >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.y >> SEC_RADIX & RADIX_MASK];
            secOffsets.z += g_waveHists[(secKeys.z >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.z >> SEC_RADIX & RADIX_MASK];
            secOffsets.w += g_waveHists[(secKeys.w >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.w >> SEC_RADIX & RADIX_MASK];
            
            thirdOffsets.x += g_waveHists[(thirdKeys.x >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.x >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.y += g_waveHists[(thirdKeys.y >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.y >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.z += g_waveHists[(thirdKeys.z >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.z >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.w += g_waveHists[(thirdKeys.w >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.w >> SEC_RADIX & RADIX_MASK];
            
            fourthOffsets.x += g_waveHists[(fourthKeys.x >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.x >> SEC_RADIX & RADIX_MASK];
            fourthOffsets.y += g_waveHists[(fourthKeys.y >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.y >> SEC_RADIX & RADIX_MASK];
            fourthOffsets.z += g_waveHists[(fourthKeys.z >> SEC_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.z >> SEC_RADIX & RADIX_MASK];
        }
        else
        {
            firstOffsets.x += g_reductionHist[firstKeys.x >> SEC_RADIX & RADIX_MASK];
            firstOffsets.y += g_reductionHist[firstKeys.y >> SEC_RADIX & RADIX_MASK];
            firstOffsets.z += g_reductionHist[firstKeys.z >> SEC_RADIX & RADIX_MASK];
            firstOffsets.w += g_reductionHist[firstKeys.w >> SEC_RADIX & RADIX_MASK];

            secOffsets.x += g_reductionHist[secKeys.x >> SEC_RADIX & RADIX_MASK];
            secOffsets.y += g_reductionHist[secKeys.y >> SEC_RADIX & RADIX_MASK];
            secOffsets.z += g_reductionHist[secKeys.z >> SEC_RADIX & RADIX_MASK];
            secOffsets.w += g_reductionHist[secKeys.w >> SEC_RADIX & RADIX_MASK];
            
            thirdOffsets.x += g_reductionHist[thirdKeys.x >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.y += g_reductionHist[thirdKeys.y >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.z += g_reductionHist[thirdKeys.z >> SEC_RADIX & RADIX_MASK];
            thirdOffsets.w += g_reductionHist[thirdKeys.w >> SEC_RADIX & RADIX_MASK];
            
            fourthOffsets.x += g_reductionHist[fourthKeys.x >> SEC_RADIX & RADIX_MASK];
            fourthOffsets.y += g_reductionHist[fourthKeys.y >> SEC_RADIX & RADIX_MASK];
            fourthOffsets.z += g_reductionHist[fourthKeys.z >> SEC_RADIX & RADIX_MASK];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        //For some bizarre reason, this is signicantly faster rolled 
        for (int i = 0; i < 4; ++i)
        {
            g_waveHists[firstOffsets[i]] = firstKeys[i];
            g_waveHists[secOffsets[i]] = secKeys[i];
            g_waveHists[thirdOffsets[i]] = thirdKeys[i];
            if (i < 3)
                g_waveHists[fourthOffsets[i]] = fourthKeys[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Lookback
        if (partitionIndex)
        {
            //Free up shared memory, because we are at max
            const uint t = g_waveHists[WAVE_INDEX];
            
            for (int i = WAVE_INDEX; i < RADIX; i += BIN_WAVES)
            {
                uint aggregate = 0;
                if (LANE == 0)
                    g_waveHists[WAVE_INDEX] = partitionIndex;
                
                for (int k = partitionIndex - LANE - 1; 0 <= k;)
                {
                    uint flagPayload = b_passTwo[i * BIN_PARTITIONS + k];
                    if (WaveActiveAllTrue((flagPayload & FLAG_MASK) > FLAG_NOT_READY))
                    {
                        if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE)
                        {
                            if (WaveIsFirstLane())
                                g_waveHists[WAVE_INDEX] = k;
                        }
                        
                        if (g_waveHists[WAVE_INDEX] < partitionIndex)
                        {
                            aggregate += WaveActiveSum(k >= g_waveHists[WAVE_INDEX] ? (flagPayload >> 2) : 0);
                                
                            if (LANE == 0)
                            {
                                InterlockedAdd(b_passTwo[i * BIN_PARTITIONS + partitionIndex], 1 ^ (aggregate << 2));
                                g_reductionHist[i] = aggregate + (i ? g_localHist[i] : 0) - g_reductionHist[i];
                            }
                            break;
                        }
                        else
                        {
                            aggregate += WaveActiveSum(flagPayload >> 2);
                            k -= LANE_COUNT;
                        }
                    }
                }
            }
            
            //place value back
            if (LANE == 0)
                g_waveHists[WAVE_INDEX] = t;
        }
        else
        {
            if (GROUP_THREAD_ID < RADIX)
                g_reductionHist[GROUP_THREAD_ID] = (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0) - g_reductionHist[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
        {
            firstKeys.x = g_waveHists[i];
            firstKeys.y = firstKeys.x >> SEC_RADIX & RADIX_MASK;
            firstKeys.z = g_reductionHist[firstKeys.y] + i;
            b_sort[firstKeys.z] = firstKeys.x;
        }
    } while (partitionIndex + BIN_TBLOCKS < BIN_PARTITIONS);
    
    //for input sizes which are not perfect multiples of the partition tile size
    if (partitionIndex == BIN_PARTITIONS - 1)
    {
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[GROUP_THREAD_ID] = (b_passTwo[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex] >> 2) + (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0);
        GroupMemoryBarrierWithGroupSync();
        
        partitionIndex++;
        for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
        {
            const uint key = b_alt[i];
        
            uint offset = 0xFFFFFFFF;
            for (int k = SEC_RADIX; k < THIRD_RADIX; ++k)
            {
                const bool t = key >> k & 1;
                offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
            }
        
            for (int k = 0; k < BIN_WAVES; ++k)
            {
                if (WAVE_INDEX == k)
                {
                    const uint t = g_reductionHist[key >> SEC_RADIX & RADIX_MASK];
                    if (countbits(offset << LANE_MASK - LANE) == 1)
                        g_reductionHist[key >> SEC_RADIX & RADIX_MASK] += countbits(offset);
                    offset = t + countbits((offset << LANE_MASK - LANE) << 1);
                }
                GroupMemoryBarrierWithGroupSync();
            }

            b_sort[offset] = key;
        }
    }
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void ThirdBinningPass(int3 gtid : SV_GroupThreadID)
{
    //load the global histogram values into shared memory
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + THIRD_RADIX_START];
    
    int partitionIndex;
    do
    {
        //atomically fetch and increment device memory index to assign partition tiles
        //Take advantage of the barrier to also clear the shared memory
        if (LANE == 0 && WAVE_INDEX == 0)
            InterlockedAdd(b_index[2], 1, g_localHist[0]);
        GroupMemoryBarrierWithGroupSync();
        partitionIndex = WaveReadLaneAt(g_localHist[0], 0);
        for (int i = GROUP_THREAD_ID; i < BIN_HISTS_SIZE; i += BIN_THREADS)
            g_waveHists[i] = 0;
        GroupMemoryBarrierWithGroupSync();
        if (partitionIndex >= BIN_PARTITIONS)
            break;
        
        //Load keys into registers
        const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
        uint4 firstKeys;
        firstKeys.x = b_sort[t];
        firstKeys.y = b_sort[t + 32];
        firstKeys.z = b_sort[t + 64];
        firstKeys.w = b_sort[t + 96];
        
        uint4 secKeys;
        secKeys.x = b_sort[t + 128];
        secKeys.y = b_sort[t + 160];
        secKeys.z = b_sort[t + 192];
        secKeys.w = b_sort[t + 224];
        
        uint4 thirdKeys;
        thirdKeys.x = b_sort[t + 256];
        thirdKeys.y = b_sort[t + 288];
        thirdKeys.z = b_sort[t + 320];
        thirdKeys.w = b_sort[t + 352];
        
        uint3 fourthKeys;
        fourthKeys.x = b_sort[t + 384];
        fourthKeys.y = b_sort[t + 416];
        fourthKeys.z = b_sort[t + 448];
        
        //Warp Level Multisplit, manually unrolled
        uint4 firstOffsets = 0xFFFFFFFF;
        for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
        {
            const bool4 t = firstKeys >> k & 1;
            firstOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            firstOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            firstOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            firstOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        uint4 bits = countbits(firstOffsets << LANE_MASK - LANE);
        int index = (firstKeys.x >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        uint prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(firstOffsets.x);
        firstOffsets.x = prev + bits.x - 1;
        
        index = (firstKeys.y >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(firstOffsets.y);
        firstOffsets.y = prev + bits.y - 1;
        
        index = (firstKeys.z >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(firstOffsets.z);
        firstOffsets.z = prev + bits.z - 1;
        
        index = (firstKeys.w >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(firstOffsets.w);
        firstOffsets.w = prev + bits.w - 1;
        
        //Second
        uint4 secOffsets = 0xFFFFFFFF;
        for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
        {
            const bool4 t = secKeys >> k & 1;
            secOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            secOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            secOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            secOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(secOffsets << LANE_MASK - LANE);
        index = (secKeys.x >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(secOffsets.x);
        secOffsets.x = prev + bits.x - 1;
        
        index = (secKeys.y >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(secOffsets.y);
        secOffsets.y = prev + bits.y - 1;
        
        index = (secKeys.z >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(secOffsets.z);
        secOffsets.z = prev + bits.z - 1;
        
        index = (secKeys.w >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(secOffsets.w);
        secOffsets.w = prev + bits.w - 1;
        
        //Third
        uint4 thirdOffsets = 0xFFFFFFFF;
        for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
        {
            const bool4 t = thirdKeys >> k & 1;
            thirdOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            thirdOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            thirdOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            thirdOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(thirdOffsets << LANE_MASK - LANE);
        index = (thirdKeys.x >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(thirdOffsets.x);
        thirdOffsets.x = prev + bits.x - 1;
        
        index = (thirdKeys.y >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(thirdOffsets.y);
        thirdOffsets.y = prev + bits.y - 1;
        
        index = (thirdKeys.z >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(thirdOffsets.z);
        thirdOffsets.z = prev + bits.z - 1;
        
        index = (thirdKeys.w >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(thirdOffsets.w);
        thirdOffsets.w = prev + bits.w - 1;
        
        uint3 fourthOffsets = 0xFFFFFFFF;
        for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
        {
            const bool3 t = fourthKeys >> k & 1;
            fourthOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            fourthOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            fourthOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
        }
        
        bits.x = countbits(fourthOffsets.x << LANE_MASK - LANE);
        bits.y = countbits(fourthOffsets.y << LANE_MASK - LANE);
        bits.z = countbits(fourthOffsets.z << LANE_MASK - LANE);
        index = (fourthKeys.x >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(fourthOffsets.x);
        fourthOffsets.x = prev + bits.x - 1;
        
        index = (fourthKeys.y >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(fourthOffsets.y);
        fourthOffsets.y = prev + bits.y - 1;
        
        index = (fourthKeys.z >> THIRD_RADIX & RADIX_MASK) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(fourthOffsets.z);
        fourthOffsets.z = prev + bits.z - 1;
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms
        if (GROUP_THREAD_ID < RADIX)
        {
            for (int k = GROUP_THREAD_ID + RADIX; k < BIN_HISTS_SIZE; k += RADIX)
            {
                g_waveHists[GROUP_THREAD_ID] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[GROUP_THREAD_ID] - g_waveHists[k];
            }
            g_reductionHist[GROUP_THREAD_ID] = g_waveHists[GROUP_THREAD_ID];
            
            if (partitionIndex == 0)
                InterlockedAdd(b_passThree[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_INCLUSIVE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
            else
                InterlockedAdd(b_passThree[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_AGGREGATE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
        }
        GroupMemoryBarrierWithGroupSync(); // a barrier must be placed between here and the lookback to prevent accidentally broadcasting an incorrect aggregate

        //exclusive prefix sum across the reductions
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_reductionHist[GROUP_THREAD_ID]) + g_reductionHist[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_reductionHist[LANE << LANE_LOG] = WavePrefixSum(g_reductionHist[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX && LANE)
            g_reductionHist[GROUP_THREAD_ID] += WaveReadLaneAt(g_reductionHist[GROUP_THREAD_ID - 1], 1); //check this later
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            firstOffsets.x += g_waveHists[(firstKeys.x >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.x >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.y += g_waveHists[(firstKeys.y >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.y >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.z += g_waveHists[(firstKeys.z >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.z >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.w += g_waveHists[(firstKeys.w >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[firstKeys.w >> THIRD_RADIX & RADIX_MASK];

            secOffsets.x += g_waveHists[(secKeys.x >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.x >> THIRD_RADIX & RADIX_MASK];
            secOffsets.y += g_waveHists[(secKeys.y >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.y >> THIRD_RADIX & RADIX_MASK];
            secOffsets.z += g_waveHists[(secKeys.z >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.z >> THIRD_RADIX & RADIX_MASK];
            secOffsets.w += g_waveHists[(secKeys.w >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[secKeys.w >> THIRD_RADIX & RADIX_MASK];
            
            thirdOffsets.x += g_waveHists[(thirdKeys.x >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.x >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.y += g_waveHists[(thirdKeys.y >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.y >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.z += g_waveHists[(thirdKeys.z >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.z >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.w += g_waveHists[(thirdKeys.w >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[thirdKeys.w >> THIRD_RADIX & RADIX_MASK];
            
            fourthOffsets.x += g_waveHists[(fourthKeys.x >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.x >> THIRD_RADIX & RADIX_MASK];
            fourthOffsets.y += g_waveHists[(fourthKeys.y >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.y >> THIRD_RADIX & RADIX_MASK];
            fourthOffsets.z += g_waveHists[(fourthKeys.z >> THIRD_RADIX & RADIX_MASK) + t] + g_reductionHist[fourthKeys.z >> THIRD_RADIX & RADIX_MASK];
        }
        else
        {
            firstOffsets.x += g_reductionHist[firstKeys.x >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.y += g_reductionHist[firstKeys.y >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.z += g_reductionHist[firstKeys.z >> THIRD_RADIX & RADIX_MASK];
            firstOffsets.w += g_reductionHist[firstKeys.w >> THIRD_RADIX & RADIX_MASK];

            secOffsets.x += g_reductionHist[secKeys.x >> THIRD_RADIX & RADIX_MASK];
            secOffsets.y += g_reductionHist[secKeys.y >> THIRD_RADIX & RADIX_MASK];
            secOffsets.z += g_reductionHist[secKeys.z >> THIRD_RADIX & RADIX_MASK];
            secOffsets.w += g_reductionHist[secKeys.w >> THIRD_RADIX & RADIX_MASK];
            
            thirdOffsets.x += g_reductionHist[thirdKeys.x >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.y += g_reductionHist[thirdKeys.y >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.z += g_reductionHist[thirdKeys.z >> THIRD_RADIX & RADIX_MASK];
            thirdOffsets.w += g_reductionHist[thirdKeys.w >> THIRD_RADIX & RADIX_MASK];
            
            fourthOffsets.x += g_reductionHist[fourthKeys.x >> THIRD_RADIX & RADIX_MASK];
            fourthOffsets.y += g_reductionHist[fourthKeys.y >> THIRD_RADIX & RADIX_MASK];
            fourthOffsets.z += g_reductionHist[fourthKeys.z >> THIRD_RADIX & RADIX_MASK];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        //For some bizarre reason, this is signicantly faster rolled 
        for (int i = 0; i < 4; ++i)
        {
            g_waveHists[firstOffsets[i]] = firstKeys[i];
            g_waveHists[secOffsets[i]] = secKeys[i];
            g_waveHists[thirdOffsets[i]] = thirdKeys[i];
            if (i < 3)
                g_waveHists[fourthOffsets[i]] = fourthKeys[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Lookback
        if (partitionIndex)
        {
            //Free up shared memory, because we are at max
            const uint t = g_waveHists[WAVE_INDEX];
            
            for (int i = WAVE_INDEX; i < RADIX; i += BIN_WAVES)
            {
                uint aggregate = 0;
                if (LANE == 0)
                    g_waveHists[WAVE_INDEX] = partitionIndex;
                
                for (int k = partitionIndex - LANE - 1; 0 <= k;)
                {
                    uint flagPayload = b_passThree[i * BIN_PARTITIONS + k];
                    if (WaveActiveAllTrue((flagPayload & FLAG_MASK) > FLAG_NOT_READY))
                    {
                        if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE)
                        {
                            if (WaveIsFirstLane())
                                g_waveHists[WAVE_INDEX] = k;
                        }
                        
                        if (g_waveHists[WAVE_INDEX] < partitionIndex)
                        {
                            aggregate += WaveActiveSum(k >= g_waveHists[WAVE_INDEX] ? (flagPayload >> 2) : 0);
                                
                            if (LANE == 0)
                            {
                                InterlockedAdd(b_passThree[i * BIN_PARTITIONS + partitionIndex], 1 ^ (aggregate << 2));
                                g_reductionHist[i] = aggregate + (i ? g_localHist[i] : 0) - g_reductionHist[i];
                            }
                            break;
                        }
                        else
                        {
                            aggregate += WaveActiveSum(flagPayload >> 2);
                            k -= LANE_COUNT;
                        }
                    }
                }
            }
            
            //place value back
            if (LANE == 0)
                g_waveHists[WAVE_INDEX] = t;
        }
        else
        {
            if (GROUP_THREAD_ID < RADIX)
                g_reductionHist[GROUP_THREAD_ID] = (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0) - g_reductionHist[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
        {
            firstKeys.x = g_waveHists[i];
            firstKeys.y = firstKeys.x >> THIRD_RADIX & RADIX_MASK;
            firstKeys.z = g_reductionHist[firstKeys.y] + i;
            b_alt[firstKeys.z] = firstKeys.x;
        }
    } while (partitionIndex + BIN_TBLOCKS < BIN_PARTITIONS);
    
    //for input sizes which are not perfect multiples of the partition tile size
    if (partitionIndex == BIN_PARTITIONS - 1)
    {
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[GROUP_THREAD_ID] = (b_passThree[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex] >> 2) + (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0);
        GroupMemoryBarrierWithGroupSync();
        
        partitionIndex++;
        for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
        {
            const uint key = b_sort[i];
        
            uint offset = 0xFFFFFFFF;
            for (int k = THIRD_RADIX; k < FOURTH_RADIX; ++k)
            {
                const bool t = key >> k & 1;
                offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
            }
        
            for (int k = 0; k < BIN_WAVES; ++k)
            {
                if (WAVE_INDEX == k)
                {
                    const uint t = g_reductionHist[key >> THIRD_RADIX & RADIX_MASK];
                    if (countbits(offset << LANE_MASK - LANE) == 1)
                        g_reductionHist[key >> THIRD_RADIX & RADIX_MASK] += countbits(offset);
                    offset = t + countbits((offset << LANE_MASK - LANE) << 1);
                }
                GroupMemoryBarrierWithGroupSync();
            }

            b_alt[offset] = key;
        }
    }
}

[numthreads(LANE_COUNT, BIN_WAVES, 1)]
void FourthBinningPass(int3 gtid : SV_GroupThreadID, int3 gid : SV_GroupID)
{
    //load the global histogram values into shared memory
    if (GROUP_THREAD_ID < RADIX)
        g_localHist[GROUP_THREAD_ID] = b_globalHist[GROUP_THREAD_ID + FOURTH_RADIX_START];
    
    int partitionIndex;
    do
    {
        //atomically fetch and increment device memory index to assign partition tiles
        //Take advantage of the barrier to also clear the shared memory
        if (LANE == 0 && WAVE_INDEX == 0)
            InterlockedAdd(b_index[3], 1, g_localHist[0]);
        GroupMemoryBarrierWithGroupSync();
        partitionIndex = WaveReadLaneAt(g_localHist[0], 0);
        for (int i = GROUP_THREAD_ID; i < BIN_HISTS_SIZE; i += BIN_THREADS)
            g_waveHists[i] = 0;
        GroupMemoryBarrierWithGroupSync();
        if (partitionIndex >= BIN_PARTITIONS)
            break;
        
        //Load keys into registers
        const int t = LANE + BIN_SUB_PART_START + BIN_PART_START;
        uint4 firstKeys;
        firstKeys.x = b_alt[t];
        firstKeys.y = b_alt[t + 32];
        firstKeys.z = b_alt[t + 64];
        firstKeys.w = b_alt[t + 96];
        
        uint4 secKeys;
        secKeys.x = b_alt[t + 128];
        secKeys.y = b_alt[t + 160];
        secKeys.z = b_alt[t + 192];
        secKeys.w = b_alt[t + 224];
        
        uint4 thirdKeys;
        thirdKeys.x = b_alt[t + 256];
        thirdKeys.y = b_alt[t + 288];
        thirdKeys.z = b_alt[t + 320];
        thirdKeys.w = b_alt[t + 352];
        
        uint3 fourthKeys;
        fourthKeys.x = b_alt[t + 384];
        fourthKeys.y = b_alt[t + 416];
        fourthKeys.z = b_alt[t + 448];
        
        //Warp Level Multisplit, manually unrolled
        uint4 firstOffsets = 0xFFFFFFFF;
        for (int k = FOURTH_RADIX; k < 32; ++k)
        {
            const bool4 t = firstKeys >> k & 1;
            firstOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            firstOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            firstOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            firstOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        uint4 bits = countbits(firstOffsets << LANE_MASK - LANE);
        int index = (firstKeys.x >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        uint prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(firstOffsets.x);
        firstOffsets.x = prev + bits.x - 1;
        
        index = (firstKeys.y >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(firstOffsets.y);
        firstOffsets.y = prev + bits.y - 1;
        
        index = (firstKeys.z >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(firstOffsets.z);
        firstOffsets.z = prev + bits.z - 1;
        
        index = (firstKeys.w >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(firstOffsets.w);
        firstOffsets.w = prev + bits.w - 1;
        
        //Second
        uint4 secOffsets = 0xFFFFFFFF;
        for (int k = FOURTH_RADIX; k < 32; ++k)
        {
            const bool4 t = secKeys >> k & 1;
            secOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            secOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            secOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            secOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(secOffsets << LANE_MASK - LANE);
        index = (secKeys.x >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(secOffsets.x);
        secOffsets.x = prev + bits.x - 1;
        
        index = (secKeys.y >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(secOffsets.y);
        secOffsets.y = prev + bits.y - 1;
        
        index = (secKeys.z >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(secOffsets.z);
        secOffsets.z = prev + bits.z - 1;
        
        index = (secKeys.w >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(secOffsets.w);
        secOffsets.w = prev + bits.w - 1;
        
        //Third
        uint4 thirdOffsets = 0xFFFFFFFF;
        for (int k = FOURTH_RADIX; k < 32; ++k)
        {
            const bool4 t = thirdKeys >> k & 1;
            thirdOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            thirdOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            thirdOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
            thirdOffsets.w &= (t.w ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.w);
        }
        
        bits = countbits(thirdOffsets << LANE_MASK - LANE);
        index = (thirdKeys.x >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(thirdOffsets.x);
        thirdOffsets.x = prev + bits.x - 1;
        
        index = (thirdKeys.y >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(thirdOffsets.y);
        thirdOffsets.y = prev + bits.y - 1;
        
        index = (thirdKeys.z >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(thirdOffsets.z);
        thirdOffsets.z = prev + bits.z - 1;
        
        index = (thirdKeys.w >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.w == 1)
            g_waveHists[index] += countbits(thirdOffsets.w);
        thirdOffsets.w = prev + bits.w - 1;
        
        uint3 fourthOffsets = 0xFFFFFFFF;
        for (int k = FOURTH_RADIX; k < 32; ++k)
        {
            const bool3 t = fourthKeys >> k & 1;
            fourthOffsets.x &= (t.x ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.x);
            fourthOffsets.y &= (t.y ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.y);
            fourthOffsets.z &= (t.z ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t.z);
        }
        
        bits.x = countbits(fourthOffsets.x << LANE_MASK - LANE);
        bits.y = countbits(fourthOffsets.y << LANE_MASK - LANE);
        bits.z = countbits(fourthOffsets.z << LANE_MASK - LANE);
        index = (fourthKeys.x >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.x == 1)
            g_waveHists[index] += countbits(fourthOffsets.x);
        fourthOffsets.x = prev + bits.x - 1;
        
        index = (fourthKeys.y >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.y == 1)
            g_waveHists[index] += countbits(fourthOffsets.y);
        fourthOffsets.y = prev + bits.y - 1;
        
        index = (fourthKeys.z >> FOURTH_RADIX) + (WAVE_INDEX << RADIX_LOG);
        prev = g_waveHists[index];
        if (bits.z == 1)
            g_waveHists[index] += countbits(fourthOffsets.z);
        fourthOffsets.z = prev + bits.z - 1;
        GroupMemoryBarrierWithGroupSync();
        
        //exclusive prefix sum across the histograms
        if (GROUP_THREAD_ID < RADIX)
        {
            for (int k = GROUP_THREAD_ID + RADIX; k < BIN_HISTS_SIZE; k += RADIX)
            {
                g_waveHists[GROUP_THREAD_ID] += g_waveHists[k];
                g_waveHists[k] = g_waveHists[GROUP_THREAD_ID] - g_waveHists[k];
            }
            g_reductionHist[GROUP_THREAD_ID] = g_waveHists[GROUP_THREAD_ID];
            
            if (partitionIndex == 0)
                InterlockedAdd(b_passFour[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_INCLUSIVE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
            else
                InterlockedAdd(b_passFour[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex], FLAG_AGGREGATE ^ (g_waveHists[GROUP_THREAD_ID] << 2));
        }
        GroupMemoryBarrierWithGroupSync(); // a barrier must be placed between here and the lookback to prevent accidentally broadcasting an incorrect aggregate

        //exclusive prefix sum across the reductions
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[(LANE + 1 & LANE_MASK) + (WAVE_INDEX << LANE_LOG)] = WavePrefixSum(g_reductionHist[GROUP_THREAD_ID]) + g_reductionHist[GROUP_THREAD_ID];
        GroupMemoryBarrierWithGroupSync();
        
        if (LANE < (RADIX >> LANE_LOG) && WAVE_INDEX == 0)
            g_reductionHist[LANE << LANE_LOG] = WavePrefixSum(g_reductionHist[LANE << LANE_LOG]);
        GroupMemoryBarrierWithGroupSync();

        if (GROUP_THREAD_ID < RADIX && LANE)
            g_reductionHist[GROUP_THREAD_ID] += WaveReadLaneAt(g_reductionHist[GROUP_THREAD_ID - 1], 1); //check this later
        GroupMemoryBarrierWithGroupSync();
        
        //Update offsets
        if (WAVE_INDEX)
        {
            const uint t = WAVE_INDEX << RADIX_LOG;
            firstOffsets.x += g_waveHists[(firstKeys.x >> FOURTH_RADIX) + t] + g_reductionHist[firstKeys.x >> FOURTH_RADIX];
            firstOffsets.y += g_waveHists[(firstKeys.y >> FOURTH_RADIX) + t] + g_reductionHist[firstKeys.y >> FOURTH_RADIX];
            firstOffsets.z += g_waveHists[(firstKeys.z >> FOURTH_RADIX) + t] + g_reductionHist[firstKeys.z >> FOURTH_RADIX];
            firstOffsets.w += g_waveHists[(firstKeys.w >> FOURTH_RADIX) + t] + g_reductionHist[firstKeys.w >> FOURTH_RADIX];

            secOffsets.x += g_waveHists[(secKeys.x >> FOURTH_RADIX) + t] + g_reductionHist[secKeys.x >> FOURTH_RADIX];
            secOffsets.y += g_waveHists[(secKeys.y >> FOURTH_RADIX) + t] + g_reductionHist[secKeys.y >> FOURTH_RADIX];
            secOffsets.z += g_waveHists[(secKeys.z >> FOURTH_RADIX) + t] + g_reductionHist[secKeys.z >> FOURTH_RADIX];
            secOffsets.w += g_waveHists[(secKeys.w >> FOURTH_RADIX) + t] + g_reductionHist[secKeys.w >> FOURTH_RADIX];
            
            thirdOffsets.x += g_waveHists[(thirdKeys.x >> FOURTH_RADIX) + t] + g_reductionHist[thirdKeys.x >> FOURTH_RADIX];
            thirdOffsets.y += g_waveHists[(thirdKeys.y >> FOURTH_RADIX) + t] + g_reductionHist[thirdKeys.y >> FOURTH_RADIX];
            thirdOffsets.z += g_waveHists[(thirdKeys.z >> FOURTH_RADIX) + t] + g_reductionHist[thirdKeys.z >> FOURTH_RADIX];
            thirdOffsets.w += g_waveHists[(thirdKeys.w >> FOURTH_RADIX) + t] + g_reductionHist[thirdKeys.w >> FOURTH_RADIX];
            
            fourthOffsets.x += g_waveHists[(fourthKeys.x >> FOURTH_RADIX) + t] + g_reductionHist[fourthKeys.x >> FOURTH_RADIX];
            fourthOffsets.y += g_waveHists[(fourthKeys.y >> FOURTH_RADIX) + t] + g_reductionHist[fourthKeys.y >> FOURTH_RADIX];
            fourthOffsets.z += g_waveHists[(fourthKeys.z >> FOURTH_RADIX) + t] + g_reductionHist[fourthKeys.z >> FOURTH_RADIX];
        }
        else
        {
            firstOffsets.x += g_reductionHist[firstKeys.x >> FOURTH_RADIX];
            firstOffsets.y += g_reductionHist[firstKeys.y >> FOURTH_RADIX];
            firstOffsets.z += g_reductionHist[firstKeys.z >> FOURTH_RADIX];
            firstOffsets.w += g_reductionHist[firstKeys.w >> FOURTH_RADIX];

            secOffsets.x += g_reductionHist[secKeys.x >> FOURTH_RADIX];
            secOffsets.y += g_reductionHist[secKeys.y >> FOURTH_RADIX];
            secOffsets.z += g_reductionHist[secKeys.z >> FOURTH_RADIX];
            secOffsets.w += g_reductionHist[secKeys.w >> FOURTH_RADIX];
            
            thirdOffsets.x += g_reductionHist[thirdKeys.x >> FOURTH_RADIX];
            thirdOffsets.y += g_reductionHist[thirdKeys.y >> FOURTH_RADIX];
            thirdOffsets.z += g_reductionHist[thirdKeys.z >> FOURTH_RADIX];
            thirdOffsets.w += g_reductionHist[thirdKeys.w >> FOURTH_RADIX];
            
            fourthOffsets.x += g_reductionHist[fourthKeys.x >> FOURTH_RADIX];
            fourthOffsets.y += g_reductionHist[fourthKeys.y >> FOURTH_RADIX];
            fourthOffsets.z += g_reductionHist[fourthKeys.z >> FOURTH_RADIX];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter keys into shared memory
        //For some bizarre reason, this is signicantly faster rolled 
        for (int i = 0; i < 4; ++i)
        {
            g_waveHists[firstOffsets[i]] = firstKeys[i];
            g_waveHists[secOffsets[i]] = secKeys[i];
            g_waveHists[thirdOffsets[i]] = thirdKeys[i];
            if (i < 3)
                g_waveHists[fourthOffsets[i]] = fourthKeys[i];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Lookback
        if (partitionIndex)
        {
            //Free up shared memory, because we are at max
            const uint t = g_waveHists[WAVE_INDEX];
            
            for (int i = WAVE_INDEX; i < RADIX; i += BIN_WAVES)
            {
                uint aggregate = 0;
                if (LANE == 0)
                    g_waveHists[WAVE_INDEX] = partitionIndex;
                
                for (int k = partitionIndex - LANE - 1; 0 <= k;)
                {
                    uint flagPayload = b_passFour[i * BIN_PARTITIONS + k];
                    if (WaveActiveAllTrue((flagPayload & FLAG_MASK) > FLAG_NOT_READY))
                    {
                        if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE)
                        {
                            if (WaveIsFirstLane())
                                g_waveHists[WAVE_INDEX] = k;
                        }
                        
                        if (g_waveHists[WAVE_INDEX] < partitionIndex)
                        {
                            aggregate += WaveActiveSum(k >= g_waveHists[WAVE_INDEX] ? (flagPayload >> 2) : 0);
                                
                            if (LANE == 0)
                            {
                                InterlockedAdd(b_passFour[i * BIN_PARTITIONS + partitionIndex], 1 ^ (aggregate << 2));
                                g_reductionHist[i] = aggregate + (i ? g_localHist[i] : 0) - g_reductionHist[i];
                            }
                            break;
                        }
                        else
                        {
                            aggregate += WaveActiveSum(flagPayload >> 2);
                            k -= LANE_COUNT;
                        }
                    }
                }
            }
            
            //place value back
            if (LANE == 0)
                g_waveHists[WAVE_INDEX] = t;
        }
        else
        {
            if (GROUP_THREAD_ID < RADIX)
                g_reductionHist[GROUP_THREAD_ID] = (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0) - g_reductionHist[GROUP_THREAD_ID];
        }
        GroupMemoryBarrierWithGroupSync();
        
        //Scatter runs of keys into device memory;
        for (int i = GROUP_THREAD_ID; i < BIN_PART_SIZE; i += BIN_THREADS)
        {
            firstKeys.x = g_waveHists[i];
            firstKeys.y = firstKeys.x >> FOURTH_RADIX;
            firstKeys.z = g_reductionHist[firstKeys.y] + i;
            b_sort[firstKeys.z] = firstKeys.x;
        }
    } while (partitionIndex + BIN_TBLOCKS < BIN_PARTITIONS);
    
    //for input sizes which are not perfect multiples of the partition tile size
    if (partitionIndex == BIN_PARTITIONS - 1)
    {
        if (GROUP_THREAD_ID < RADIX)
            g_reductionHist[GROUP_THREAD_ID] = (b_passFour[GROUP_THREAD_ID * BIN_PARTITIONS + partitionIndex] >> 2) + (GROUP_THREAD_ID ? g_localHist[GROUP_THREAD_ID] : 0);
        GroupMemoryBarrierWithGroupSync();
        
        partitionIndex++;
        for (int i = GROUP_THREAD_ID + BIN_PART_START; i < e_size; i += BIN_THREADS)
        {
            const uint key = b_alt[i];
        
            uint offset = 0xFFFFFFFF;
            for (int k = FOURTH_RADIX; k < 32; ++k)
            {
                const bool t = key >> k & 1;
                offset &= (t ? 0 : 0xFFFFFFFF) ^ WaveActiveBallot(t);
            }
        
            for (int k = 0; k < BIN_WAVES; ++k)
            {
                if (WAVE_INDEX == k)
                {
                    const uint t = g_reductionHist[key >> FOURTH_RADIX];
                    if (countbits(offset << LANE_MASK - LANE) == 1)
                        g_reductionHist[key >> FOURTH_RADIX] += countbits(offset);
                    offset = t + countbits((offset << LANE_MASK - LANE) << 1);
                }
                GroupMemoryBarrierWithGroupSync();
            }

            b_sort[offset] = key;
        }
    }
}